{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2022982-581f-4b0c-87cc-5a0f977da3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1573c0-bcfc-4912-823d-508d75bf79d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import time,os,sys,traceback,contextlib, inspect\n",
    "from fastcore.basics import *\n",
    "from fastcore.imports import *\n",
    "from fastcore.foundation import *\n",
    "from fastcore.parallel import *\n",
    "from fastcore.script import *\n",
    "\n",
    "\n",
    "from nbprocess.read import *\n",
    "from nbprocess.doclinks import *\n",
    "from nbprocess.process import NBProcessor\n",
    "from logging import warning\n",
    "\n",
    "from execnb.nbio import *\n",
    "from execnb.shell import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084506e-4393-41eb-8057-9406e78e4079",
   "metadata": {},
   "source": [
    "# Test Notebooks\n",
    "> Run unit tests on notebooks in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4fa1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def test_nb(fn, skip_flags=None, force_flags=None, do_print=False, showerr=True):\n",
    "    \"Execute tests in notebook in `fn` except those with `skip_flags`\"\n",
    "    if not IN_NOTEBOOK: os.environ[\"IN_TEST\"] = '1'\n",
    "    flags=set(L(skip_flags)) - set(L(force_flags))\n",
    "    nb = NBProcessor(fn, process=True).nb\n",
    "\n",
    "    def _no_eval(cell):\n",
    "        if cell.cell_type != 'code': return True\n",
    "        direc = getattr(cell, 'directives_', {}) or {}\n",
    "        if direc.get('eval:', [''])[0].lower() == 'false': return True\n",
    "        return flags & direc.keys()\n",
    "    \n",
    "    start = time.time()\n",
    "    k = CaptureShell(fn)\n",
    "    if do_print: print(f'Starting {fn}')\n",
    "    try:\n",
    "        k.run_all(nb, exc_stop=True, preproc=_no_eval)\n",
    "        res = True\n",
    "    except: \n",
    "        if showerr: warning(k.prettytb(fname=fn))\n",
    "        res=False\n",
    "    if do_print: print(f'- Completed {fn}')\n",
    "    return res,time.time()-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc26b80-6e4e-4a16-bcde-dd4d156289e5",
   "metadata": {},
   "source": [
    "`test_nb` can test a notebook, and skip over certain flags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf84ef-bce4-4531-80df-7a4e514a7ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_nb = Path('../tests/directives.ipynb')\n",
    "success,duration = test_nb(_nb, skip_flags=['notest'])\n",
    "assert success\n",
    "duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46117f38",
   "metadata": {},
   "source": [
    "In that notebook the cell flagged *notest* raises an exception, which will be returned as a `bool`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f521b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_nb = Path('../tests/directives.ipynb')\n",
    "success,duration = test_nb(_nb, showerr=False)\n",
    "assert not success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bf1f1b-935d-4b69-ba96-827c5d7213f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _keep_file(fname:str, # filename for which to check for `indicator_fname`\n",
    "               ignore_fname:str # filename that will result in siblings being ignored\n",
    "                ) -> bool:\n",
    "    \"Returns False if `indicator_fname` is a sibling to `fname` else True\"\n",
    "    p = Path(fname)\n",
    "    if p.exists(): return not bool(p.parent.ls().attrgot('name').filter(lambda x: x == ignore_fname))\n",
    "    else: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b22546-d93f-41b5-b1b3-5bc1a8ab556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not _keep_file('../tests/notest/nb_ignore.ipynb', ignore_fname='.notest') # has sibling file named .notest\n",
    "assert _keep_file('../tests/minimal.ipynb', ignore_fname='.notest') # does not have a sibling file named .notest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ef30c3-38ee-4c77-93df-c1ae4f959eb1",
   "metadata": {},
   "source": [
    "Sometimes you may wish to override one or more of the skip_flags, in which case you can use the argument `force_flags` which will remove the appropriate tag(s) from `skip_flags`.  This is useful because `skip_flags` are meant to be set in the `tst_flags` field of `settings.ini`, whereas `force_flags` are usually passed in by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cc6a61-a48e-4ab1-89a9-18316ca795d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def nbprocess_test(\n",
    "    fname:str=None,  # A notebook name or glob to test\n",
    "    flags:str='',  # Space separated list of test flags you want to run that are normally ignored\n",
    "    n_workers:int=None,  # Number of workers to use\n",
    "    timing:bool=False,  # Timing each notebook to see the ones are slow\n",
    "    do_print:str=False, # Print start and end of each NB\n",
    "    pause:float=0.01,  # Pause time (in secs) between notebooks to avoid race conditions\n",
    "    ignore_fname:str='.notest' # filename that will result in siblings being ignored\n",
    "):\n",
    "    \"Test in parallel the notebooks matching `fname`, passing along `flags`\"\n",
    "    skip_flags = config_key('tst_flags', '', path=False).split()\n",
    "    force_flags = flags.split()\n",
    "    files = [Path(f).absolute() for f in sorted(nbglob(fname)) if _keep_file(f, ignore_fname)]\n",
    "    if len(files)==0:\n",
    "        print('No files were eligible for testing')\n",
    "        return\n",
    "    if n_workers is None: n_workers = 0 if len(files)==1 else min(num_cpus(), 8)\n",
    "    os.chdir(config_key(\"nbs_path\"))\n",
    "    results = parallel(test_nb, files, skip_flags=skip_flags, force_flags=force_flags, n_workers=n_workers, pause=pause, do_print=do_print)\n",
    "    passed,times = zip(*results)\n",
    "    if all(passed): print(\"Success.\")\n",
    "    else: \n",
    "        _fence = '='*50\n",
    "        failed = '\\n\\t'.join(f.name for p,f in zip(passed,files) if not p)\n",
    "        sys.stderr.write(f\"\\nnbprocess Tests Failed On The Following Notebooks:\\n{_fence}\\n\\t{failed}\")\n",
    "        exit(1)\n",
    "    if timing:\n",
    "        for i,t in sorted(enumerate(times), key=lambda o:o[1], reverse=True): print(f\"{files[i].name}: {int(t)} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e0542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval:false\n",
    "nbprocess_test(n_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee3f4db",
   "metadata": {},
   "source": [
    "## Eval -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a32f1-8884-497e-a1af-dd38c80d8873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbprocess.doclinks import nbprocess_export\n",
    "nbprocess_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f62c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
